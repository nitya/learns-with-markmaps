# Dec 2024

---

## 1. Overview 
### 1.1 What is Azure AI Foundry? 
### 1.2 Azure AI Foundry architecture
### 1.3 Azure OpenAI in Azure AI Foundry
### 1.4 Management center
### 1.5 Azure AI Foundry SDK
### 1.6 Region support
### 1.7 Azure AI FAQ
### 1.8 Which studio should I choose?

---

## 2. Quickstarts
### 2.1 Use the chat playground
### 2.2 Build a chat app using the Azure AI SDK
### 2.3 Get started using Azure OpenAI Assistants

---

## 3. Tutorials

### 3.1 Deploy an enterprise chat web app
### 3.2 Build a custom chat app with the Azure AI Foundry SDK
#### 3.2.1 Set up project and install SDK
#### 3.2.2 Build with data retrieval
#### 3.2.3 Evaluate the chat app
### 3.3 What are AI services?

---

## 4. How-To

### 4.1 Azure OpenAI and AI Services 
#### 4.1.1 What are AI services?
#### 4.1.2 Use Azure AI services in Azure AI Foundry portal
#### 4.1.3 Azure OpenAI
##### 4.1.3.1 What is Azure OpenAI?
##### 4.1.3.2 Use Azure OpenAI Service in Azure AI Foundry portal
##### 4.1.3.3 Deploy Azure OpenAI models
##### 4.1.3.4 Fine-tune Azure OpenAI models
##### 4.1.3.5 Get started using Azure OpenAI Assistants
##### 4.1.3.6 Use GPT-4o in the real-time audio playground
##### 4.1.3.7 Analyze images and video with GPT-4 for Vision in the playground
##### 4.1.3.8 Use your image data with Azure OpenAI
#### 4.1.4 Azure AI Speech
##### 4.1.4.1 Real-time speech to text
##### 4.1.4.2 Pronunciation assessment
##### 4.1.4.3 Hear and speak with chat in the playground
##### 4.1.4.4 Fine-tune in Azure AI Foundry portal for custom speech

### 4.2 Explore and select AI models
#### 4.2.1 Model catalog
#### 4.2.2 Data, privacy, and security for Model Catalog
#### 4.2.3 Model lifecycle and retirement
#### 4.2.4 Model Benchmarking
##### 4.2.4.1 Model benchmarks
##### 4.2.4.2 How to use model benchmarking
#### 4.2.5 Fine-tune Models
##### 4.2.5.1 Fine-tuning overview
##### 4.2.5.2 Fine-tune with user-managed compute
##### 4.2.5.3 Fine-tune Azure OpenAI models
#### 4.2.6 Distillation
#### 4.2.7 Azure OpenAI Models
##### 4.2.7.1 Deploy Azure OpenAI models
##### 4.2.7.2 Fine-tune Azure OpenAI models
#### 4.2.8 Healthcare AI models
##### 4.2.8.1 Foundational AI models for healthcare
##### 4.2.8.2 MedImageInsight - embedding model
##### 4.2.8.3 CXRReportGen - text generation model
##### 4.2.8.4 MedImageParse - prompted segmentation model
#### 4.2.9 Microsoft Phi family models
##### 4.2.9.1 Phi-3 chat models
##### 4.2.9.2 Phi-3 chat model with vision
##### 4.2.9.3 Phi-3.5 chat model with vision
##### 4.2.9.4 Phi-4 chat models
##### 4.2.9.5 Fine-tune Phi-3 chat models

#### 4.2.10 Cohere models
##### 4.2.10.1 Cohere Command models
##### 4.2.10.2 Cohere Embed models
##### 4.2.10.3 Cohere Rerank models
#### 4.2.11 Meta Llama models
##### 4.2.11.1 Meta Llama family models
##### 4.2.11.2 Fine-tune Meta Llama family models
#### 4.2.12 JAIS model
#### 4.2.13 Jamba models
#### 4.2.14 TimeGEN-1 model
#### 4.2.15 NTTDATA tsuzumi model
#### 4.2.16 Fine-tune tsuzumi model

### 4.3 Deploy AI models
#### 4.3.1 Deployments overview
#### 4.3.2 Azure AI Model Inference
##### 4.3.2.1 What is the Azure AI model inference service?
##### 4.3.2.2 Upgrade from GitHub Models
##### 4.3.2.3 Add and configure models
##### 4.3.2.4 Deployment types
##### 4.3.2.5 Use the inference endpoint
##### 4.3.2.6 Quotas and limits
##### 4.3.2.7 Azure AI model inference FAQ
#### 4.3.3
##### 4.3.3.1 Deploy models as serverless API
##### 4.3.3.2 Consume serverless API models from a different project or hub
##### 4.3.3.3 Model and region availability for Serverless API deployments
##### 4.3.4 Managed compute

### 4.4 Create a project

### 4.5 Manage projects and hubs
#### 4.5.1 Hubs and projects overview
#### 4.5.2 Create your first hub
#### 4.5.3 Create a hub using the Azure Machine Learning SDK and CLI
#### 4.5.4 Create a hub in the Azure portal
#### 4.5.5 Create a hub from template
#### 4.5.6 Create a hub using Terraform
#### 4.5.7 Create and manage compute

### 4.6 Connections
#### 4.6.1 Connections overview
#### 4.6.2 Create a connection
#### 4.6.3 Create a connection using the Azure Machine Learning SDK

### 4.7 Data for your generative AI app
#### 4.7.1 Overview of retrieval augmented generation (RAG)
#### 4.7.2 Add data to your project
#### 4.7.3 Build and consume vector indexes
#### 4.7.4 Build and consume indexes using code
#### 4.7.5 Synthetic Data Generation

### 4.8 Develop generative AI apps
#### 4.8.1 Develop in Azure AI Foundry Portal 
##### 4.8.1.1 Build apps with prompt flow
###### 4.8.1.1.1 Prompt flow overview
###### 4.8.1.1.2 Develop flows
- Create and manage compute session
- Create a flow
- Tune prompts using variants
- Process images in a flow
- Use prompt flow tools
    - Prompt flow tools overview
    - LLM tool
    - Prompt tool
    - Python tool
    - Azure OpenAI GPT-4 Turbo with Vision tool
    - Index Lookup tool
    - Rerank tool
    - Content Safety tool
    - Embedding tool
    - Serp API tool
###### 4.8.1.1.3 Troubleshoot prompt flow

#### 4.8.2 Develop with code
##### 4.8.2.1 Work with projects in VS Code
##### 4.8.2.2 Start with an AI template
##### 4.8.2.3 Develop with LangChain
##### 4.8.2.4 Develop with LlamaIndex
##### 4.8.2.5 Develop with Semantic Kernel

#### 4.8.3 Trace Generative AI apps
##### 4.8.3.1 Tracing overview
##### 4.8.3.2 Trace your application with Azure AI Inference SDK
##### 4.8.3.3 Visualize your traces


### 4.9 Evaluate generative AI apps
#### 4.9.1 Evaluations Concepts
#### 4.9.2 Evaluation of generative AI models and AI applications
#### 4.9.3 Evaluation and monitoring metrics for generative AI
#### 4.9.4 Manually evaluate prompts in the playground
#### 4.9.5 Generate synthetic and simulated data for evaluation
#### 4.9.6 Evaluate with the Azure AI Evaluation SDK
#### 4.9.7 Run evaluations from the portal
#### 4.9.8 View evaluation results in the portal
#### 4.9.9 Evaluate flows in the portal 
##### 4.9.9.1 Submit batch run and evaluate a flow
##### 4.9.9.2 Develop an evaluation flow in Prompt flow
#### 4.9.10 A/B experimentation

### 4.10 Deploy and monitor generative AI apps
#### 4.10.1 Continuously monitor your applications
#### 4.10.2 Deploy & Monitor flows
##### 4.10.2.1 Deploy a flow for real-time inference
##### 4.10.2.2 Enable tracing and collect feedback for a flow deployment
##### 4.10.2.3 Monitor prompt flow deployments
##### 4.10.2.4 Troubleshoot deployments and monitoring


### 4.11 Costs and quotas
#### 4.11.1 Plan and manage costs
#### 4.11.2 Manage quotas
#### 4.11.3 Increase rate limit

---

## 5. Security & Governance

### 5.1 Identity & Access Management
#### 5.1.1 Role-based access control in Azure AI Foundry portal

### 5.2 Network Security
#### 5.2.1 Configure managed network
#### 5.2.2 Configure private link
#### 5.2.3 Secure playground chat
#### 5.2.4 Securely access on-premises resources
#### 5.2.5 Troubleshoot secure project connectivity

### 5.3 Data Protection & Encryption
#### 5.3.1 Configure customer-managed keys
#### 5.3.2 Rotate keys
#### 5.3.3 Disable shared key access to storage

### 5.4 Azure Policies
#### 5.4.1 Built-in policy to allow specific models
#### 5.4.2 Custom policy to allow specific models

### 5.5 Vulnerability management
### 5.6 Disaster recovery
### 5.7 Security baseline

---

## 6. Responsible AI

### 6.1 Responsible AI overview
### 6.2 What is Azure AI Content Safety?
### 6.3 Use Azure AI Content Safety in the portal
### 6.4 Content filtering
### 6.5 Use blocklists
### 6.6 Transparency notes for Azure AI Services
### 6.7 Limited Access features
### 6.8 System message templates
### 6.9 Transparency Note for safety evaluations

---

## 7. Reference

### 7.1 Azure AI Projects SDK
### 7.2 Azure Machine Learning Python SDK
### 7.3 Azure Machine Learning REST API
### 7.4 Azure AI services SDKs
### 7.5 Azure AI services REST APIs
### 7.6 Prompt flow Python SDK
### 7.7 Azure AI Model Inference API
#### 7.7.1 What's the Azure AI Model Inference API?
#### 7.7.2 Reference
##### 7.7.2.1 Get Info
##### 7.7.2.2 Embeddings
##### 7.7.2.3 Completions
##### 7.7.2.4 Chat Completions
##### 7.7.2.5 Images Embeddings
### 7.9.Azure Policy built-ins

---

## 8. Resources

### 8.1 Support & help options
### 8.2 Use Azure AI Foundry with a screen reader
### 8.3 Region support
### 8.4 Azure updates
### 8.5 Pricing calculator
### 8.6 Compliance
### 8.7 Service Level Agreement (SLA)
### 8.8 Azure Government
### 8.9 Videos
### 8.10 Azure Blog
### 8.11 Artificial Intelligence and Machine Learning Blog
### 8.12 LLMOps with Prompt Flow

---

